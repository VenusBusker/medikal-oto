name: Tıp Haberleri Canlı Akış ve Arşiv
on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout depo
        uses: actions/checkout@v3

      - name: Haberleri Çek
        run: |
          # Geniş sorgu, ama Python içinde Kasım 2025 filtresi uygulayacağız
          QUERY="organ+transplant+OR+prosthetic+OR+bionic+OR+neural+interface"
          curl -L -s "https://news.google.com/rss/search?q=$QUERY&hl=en-US&gl=US&ceid=US:en" > google_news.xml
          
      - name: Filtrele ve Birleştir
        shell: python
        run: |
          import json, os, re
          from datetime import datetime

          def get_val(item, tag):
              match = re.search(f'<{tag}>(.*?)</{tag}>', item, re.DOTALL)
              return match.group(1) if match else ""

          new_items = []
          # Filtre başlangıcı: 1 Kasım 2025
          limit_date = datetime(2025, 11, 1)

          if os.path.exists('google_news.xml'):
              with open('google_news.xml', 'r', encoding='utf-8') as f:
                  content = f.read()
                  items = re.findall(r'<item>(.*?)</item>', content, re.DOTALL)
                  for it in items:
                      pub_date_str = get_val(it, 'pubDate')
                      try:
                          # Tarihi formatla ve karşılaştır
                          dt = datetime.strptime(pub_date_str, '%a, %d %b %Y %H:%M:%S %Z')
                          if dt >= limit_date:
                              title = get_val(it, 'title').replace('<![CDATA[', '').replace(']]>', '')
                              link = get_val(it, 'link')
                              new_items.append({'title': title, 'link': link, 'pubDate': pub_date_str})
                      except:
                          continue

          old_items = []
          if os.path.exists('haberler.json'):
              try:
                  with open('haberler.json', 'r') as f:
                      old_data = json.load(f)
                      old_items = old_data.get('items', [])
              except: pass

          existing_links = {item.get('link') for item in old_items}
          unique_new = [item for item in new_items if item.get('link') not in existing_links]
          
          # Birleştir (En günceller her zaman en üstte kalır)
          combined = unique_new + old_items
          with open('haberler.json', 'w') as f:
              json.dump({"status": "ok", "items": combined[:1000]}, f, indent=2)

      - name: Değişiklikleri Kaydet
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add haberler.json
          git commit -m "Kasim 2025 Sonrasi Guncelleme: $(date)" || exit 0
          git push origin main
